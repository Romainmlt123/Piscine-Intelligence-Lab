# Documentation v1.4.0 - Streaming TTS et RAG Multi-Agent

## Vue d'ensemble

Cette documentation retrace les amÃ©liorations apportÃ©es au systÃ¨me de Professeur IA Vocal, notamment l'optimisation de la latence, le streaming TTS, et l'architecture multi-modÃ¨le par matiÃ¨re.

---

## 1. ProblÃ¨mes initiaux identifiÃ©s

### 1.1 Audio qui se superpose
**SymptÃ´me** : Plusieurs chunks audio se jouaient simultanÃ©ment, rendant le son incomprÃ©hensible.

**Causes racines** :
1. **Pas de backpressure** : Le serveur envoyait les chunks plus vite que le client ne pouvait les jouer
2. **Race condition** dans le frontend : Le flag `isPlayingAudio` Ã©tait vÃ©rifiÃ© avant que `.play()` ne soit rÃ©solu
3. **Aucune coordination** : Pas de mÃ©canisme d'indexation des chunks

### 1.2 TTFA (Time To First Audio) trop Ã©levÃ©
**SymptÃ´me** : 80+ secondes avant d'entendre le premier son.

**Causes** :
1. Le `SentenceBuffer` attendait des phrases trop longues (150+ caractÃ¨res)
2. Piper TTS prend ~2-3s par chunk sur CPU
3. Le LLM gÃ©nÃ©rait des rÃ©ponses trÃ¨s longues

### 1.3 STT qui tronque les phrases
**SymptÃ´me** : "Ã©quation du second degrÃ©" Ã©tait transcrit comme "du second degrÃ©".

**Cause** : VAD trop agressif (mode 3) avec padding insuffisant (300ms).

---

## 2. Solutions implÃ©mentÃ©es

### 2.1 Architecture Audio Streaming

#### Nouveau module `audio_streamer.py`

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          SERVER                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚   LLM   â”‚â”€â”€â”€â–ºâ”‚ Text Buffer â”‚â”€â”€â”€â–ºâ”‚   TTS   â”‚                 â”‚
â”‚  â”‚ Stream  â”‚    â”‚ (Sentences) â”‚    â”‚  Piper  â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                 â”‚
â”‚                                         â”‚                       â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                     â”‚     AudioStreamManager                â”‚  â”‚
â”‚                     â”‚  (Thread-safe FIFO, indexed chunks)   â”‚  â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼ WebSocket (indexed)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          CLIENT                                 â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                     â”‚         AudioPlayer Class             â”‚  â”‚
â”‚                     â”‚  - Queue ordonnÃ©e par index           â”‚  â”‚
â”‚                     â”‚  - await sur audio.play()             â”‚  â”‚
â”‚                     â”‚  - onended avant chunk suivant        â”‚  â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Composants clÃ©s** :
- **AudioStreamManager** : Worker TTS dans un thread sÃ©parÃ©, queue FIFO thread-safe
- **SentenceBuffer** : DÃ©coupe le texte sur les frontiÃ¨res sÃ©mantiques (`.`, `!`, `?`, `,`)
- **AudioPlayer (JS)** : Classe avec queue triÃ©e par index et playback bloquant

#### Fichiers modifiÃ©s
- `audio_streamer.py` (NOUVEAU)
- `server.py` : IntÃ©gration AudioStreamManager, envoi `audio_chunk_meta` + `audio_reset`
- `static/index.html` : Classe AudioPlayer avec gestion d'index

---

### 2.2 Optimisation TTFA

| ParamÃ¨tre | Avant | AprÃ¨s | Impact |
|-----------|-------|-------|--------|
| SentenceBuffer `min_chars` | 150 | 5 | Chunks plus petits, plus rapides |
| SentenceBuffer `max_chars` | 200 | 50 | Force le dÃ©coupage |
| Premier chunk threshold | 20 | 5 | Premier audio ultra-rapide |
| Prompts LLM | Longs | "Sois CONCIS. Phrases COURTES." | RÃ©ponses plus courtes |

**RÃ©sultat** : TTFA passÃ© de **80s** Ã  **~15-25s** â¬‡ï¸

---

### 2.3 Correction VAD

| ParamÃ¨tre | Avant | AprÃ¨s |
|-----------|-------|-------|
| AgressivitÃ© | 3 (max) | 2 (medium-high) |
| Padding | 300ms | 600ms |

**RÃ©sultat** : Phrases capturÃ©es complÃ¨tement.

---

### 2.4 Architecture Multi-ModÃ¨le par MatiÃ¨re

#### Configuration des agents

| MatiÃ¨re | ModÃ¨le LLM | RAG Collection | Couleur Badge |
|---------|------------|----------------|---------------|
| ğŸ”µ MATH | `qwen2.5:1.5b` | `math_agent` | Bleu |
| ğŸ”´ PHYSICS | `llama3.2:1b` | `physics_agent` | Rouge |
| ğŸŸ¢ ENGLISH | `gemma:2b` | `english_agent` | Vert |
| ğŸŸ£ GENERAL | `qwen2.5:1.5b` | - | Violet |

#### Routing intelligent

1. **Keyword Matching** (rapide) : DÃ©tection par mots-clÃ©s
   - Math : Ã©quation, calcul, algÃ¨bre, xÂ², dÃ©rivÃ©e...
   - Physics : gravitÃ©, force, newton, Ã©nergie...
   - English : grammar, tense, vocabulary, conjugation...

2. **LLM Fallback** (lent) : Si aucun keyword, le LLM classifie

#### Fichiers modifiÃ©s
- `orchestrator.py` : 4 instances LLM, 3 RAG modules, routing ENGLISH
- `llm_module.py` : Ajout `model_name` property
- `server.py` : Envoi du `model_name` dans les events
- `static/index.html` : Affichage modÃ¨le dans le badge

---

### 2.5 Math-to-Speech

#### Nouveau module `math_to_speech.py`

Convertit les symboles mathÃ©matiques en franÃ§ais parlÃ© **avant** le TTS.

| Symbole | Conversion |
|---------|------------|
| `xÂ²` | "x au carrÃ©" |
| `xÂ³` | "x au cube" |
| `x^n` | "x puissance n" |
| `âˆš` | "racine carrÃ©e de" |
| `=` | "Ã©gale" |
| `+` `-` `Ã—` `Ã·` | "plus" "moins" "multipliÃ© par" "divisÃ© par" |
| `Ï€` `Î¸` `Î±` | "pi" "thÃªta" "alpha" |
| `âˆ«` `âˆ‘` | "intÃ©grale de" "somme de" |
| `1/2` | "un demi" |
| `xâ‚` | "x indice 1" |

**Exemple** :
```
EntrÃ©e:  "xÂ² + 2x - 4 = 0"
Sortie:  "x au carrÃ© plus 2x moins 4 Ã©gale, 0"
```

---

## 3. Knowledge Base

### Structure des dossiers
```
knowledge_base/
â”œâ”€â”€ math/
â”‚   â””â”€â”€ equations.txt       # Ã‰quations du second degrÃ©
â”œâ”€â”€ physics/
â”‚   â””â”€â”€ gravitation.txt     # Loi de la gravitation
â””â”€â”€ english/
    â”œâ”€â”€ grammar_basics.txt  # Present simple, perfect, etc.
    â””â”€â”€ vocabulary.txt      # Idioms, connectors
```

---

## 4. MÃ©triques de performance

### Latence typique (CPU only)

| Ã‰tape | DurÃ©e |
|-------|-------|
| STT (Whisper base) | 3-6s |
| Routing (keywords) | ~0s |
| Routing (LLM fallback) | ~10s |
| RAG | 0.3-0.5s |
| **TTFA** | **15-25s** |
| LLM total | 20-80s (selon longueur) |
| TTS par chunk | 2-3s |

### Bottlenecks identifiÃ©s

1. **LLM sur CPU** : Le temps de gÃ©nÃ©ration du premier token est Ã©levÃ©
2. **Piper TTS sur CPU** : ~2-3s par phrase
3. **Whisper sur CPU** : ~4-6s par transcription

### Recommandations pour aller plus loin

- **GPU** : AccÃ©lÃ©rerait tout de 5-10x
- **Whisper tiny** : Plus rapide mais moins prÃ©cis
- **TTS espeak** : InstantanÃ© mais voix robotique
- **ModÃ¨les quantifiÃ©s** : Q4_K_M pour rÃ©duire la mÃ©moire

---

## 5. API WebSocket

### Messages serveur â†’ client

| Type | Description |
|------|-------------|
| `user_text` | Transcription STT |
| `ai_text_chunk` | Token LLM (streaming) |
| `ai_text` | Texte complet final |
| `rag_sources` | Contexte RAG utilisÃ© |
| `audio_reset` | Reset du player audio |
| `audio_chunk_meta` | MÃ©tadonnÃ©es chunk (index) |
| `latency_metrics` | MÃ©triques de performance |
| (binary) | DonnÃ©es audio WAV |

---

## 6. Fichiers modifiÃ©s/crÃ©Ã©s

### Nouveaux fichiers
- `audio_streamer.py` - Gestion streaming audio
- `math_to_speech.py` - Conversion maths â†’ parole
- `knowledge_base/english/` - Documents anglais
- `docs/model_choices.md` - Documentation modÃ¨les

### Fichiers modifiÃ©s
- `server.py` - IntÃ©gration AudioStreamManager
- `orchestrator.py` - Multi-modÃ¨le, ENGLISH
- `llm_module.py` - model_name property
- `vad_module.py` - AgressivitÃ© rÃ©duite
- `static/index.html` - AudioPlayer class, badges colorÃ©s

---

## 7. Commandes utiles

```bash
# DÃ©marrer le serveur
./start.sh

# Lister les modÃ¨les Ollama
ollama list

# Installer un nouveau modÃ¨le
ollama pull <model_name>

# Tester math-to-speech
source venv/bin/activate
python -c "from math_to_speech import convert_math_to_speech; print(convert_math_to_speech('xÂ² = 4'))"
```

---

## 8. Prochaines Ã©tapes possibles

1. **GPU Support** : Activer CUDA pour Whisper/LLM/TTS
2. **Voix personnalisÃ©e** : EntraÃ®ner une voix Piper custom
3. **Multi-langue** : DÃ©tecter la langue et adapter TTS
4. **Historique conversation** : Persister les Ã©changes
5. **UI amÃ©liorÃ©e** : Visualisation formules LaTeX
